import replicate
import time
import logging

# Initialize debounce variables
last_call_time = 0
debounce_interval = 2  # Set the debounce interval (in seconds) to your desired value

def debounce_replicate_run(llm, prompt, max_len, temperature, top_p, API_TOKEN,model_reference):
    global last_call_time
    print("last call time: ", last_call_time)

    # Get the current time
    current_time = time.time()

    # Calculate the time elapsed since the last call
    elapsed_time = current_time - last_call_time

    # Check if the elapsed time is less than the debounce interval
    if elapsed_time < debounce_interval:
        print("Debouncing")
        return "Hello! You are sending requests too fast. Please wait a few seconds before sending another request."

    # Update the last call time to the current time
    last_call_time = time.time()

    try:
        # Replace with the correct model reference
        model_reference = model_reference
        print("The API_TOKEN", API_TOKEN)

        # Initialize a client object with API token
        client = replicate.Client(api_token=API_TOKEN)

        # Attempt to call the Replicate API
        output = client.run(
            model_reference,
            input={"prompt": prompt + "Assistant: ", "max_length": max_len, "temperature": temperature, "top_p": top_p, "repetition_penalty": 1}
        )
        return output
    except replicate.exceptions.ReplicateError as e:
        # Handle specific Replicate errors
        logging.error(f"ReplicateError: {e}")
        logging.error(f"Title: {e.title}")
        logging.error(f"Status Code: {e.status}")
        logging.error(f"Detail: {e.detail}")
        return f"ReplicateError: {e.title} - {e.detail}"
    except Exception as e:
        # Handle other exceptions
        logging.exception("Error calling Replicate API:")
        return "An error occurred while communicating with the LLaMA2 model. Please try again later."



import streamlit as st
import os
import replicate
from dotenv import load_dotenv
import os

# Load environment variables from .env file
load_dotenv()
from utils import debounce_replicate_run

REPLICATE_API_TOKEN = os.getenv("REPLICATE_API_TOKEN")
REPLICATE_MODEL_ENDPOINTS = {
    'LLaMA2-7B': os.getenv('REPLICATE_MODEL_ENDPOINT7B', default=''),
    'LLaMA2-13B': os.getenv('REPLICATE_MODEL_ENDPOINT13B', default=''),
    'LLaMA2-70B': os.getenv('REPLICATE_MODEL_ENDPOINT70B', default='')
}


print("The API TOKEN IS",REPLICATE_API_TOKEN)
print("The MODEL ENDPOINTS ARE",REPLICATE_MODEL_ENDPOINTS)

# Set Pre-prompt
PRE_PROMPT = "You are a helpful assistant. You do not respond as 'User' or pretend to be 'User'. You only respond once as Assistant."

# Set initial page configuration
st.set_page_config(page_title="LLaMA2 Chatbot", page_icon=":left_speech_bubble:", layout="wide")

def render_app():
    # Set up containers
    response_container = st.container()
    container = st.container()

    # Set up Session State variables
    st.session_state.setdefault('chat_dialogue', [])
    st.session_state.setdefault('llm', REPLICATE_MODEL_ENDPOINTS['LLaMA2-70B'])
    st.session_state.setdefault('temperature', 0.1)
    st.session_state.setdefault('top_p', 0.9)
    st.session_state.setdefault('max_seq_len', 512)
    st.session_state.setdefault('pre_prompt', PRE_PROMPT)
    st.session_state.setdefault('string_dialogue', '')

    # Set up left sidebar
    st.sidebar.header("Blog Chatbot ðŸ’¬")
   
     #container for the chat history
    response_container = st.container()
    #container for the user's text input
    container = st.container()
    #Set up/Initialize Session State variables:
    if 'chat_dialogue' not in st.session_state:
        st.session_state['chat_dialogue'] = []
    if 'llm' not in st.session_state:
        #st.session_state['llm'] = REPLICATE_MODEL_ENDPOINT13B
        st.session_state['llm'] = 'LLaMA2-70B'
    if 'temperature' not in st.session_state:
        st.session_state['temperature'] = 0.1
    if 'top_p' not in st.session_state:
        st.session_state['top_p'] = 0.9
    if 'max_seq_len' not in st.session_state:
        st.session_state['max_seq_len'] = 512
    if 'pre_prompt' not in st.session_state:
        st.session_state['pre_prompt'] = PRE_PROMPT
    if 'string_dialogue' not in st.session_state:
        st.session_state['string_dialogue'] = ''

    #Dropdown menu to select the model edpoint:
    selected_option = st.sidebar.selectbox('Choose a LLaMA2 model:', ['LLaMA2-70B', 'LLaMA2-13B', 'LLaMA2-7B'], key='model')
    if selected_option == 'LLaMA2-7B':
        st.session_state['llm'] = 'LLaMA2-7B'
    elif selected_option == 'LLaMA2-13B':
        st.session_state['llm'] = 'LLaMA2-13B'
    else:
        st.session_state['llm'] = 'LLaMA2-70B'
    #Model hyper parameters:
    st.session_state['temperature'] = st.sidebar.slider('Temperature:', min_value=0.01, max_value=5.0, value=0.1, step=0.01)
    st.session_state['top_p'] = st.sidebar.slider('Top P:', min_value=0.01, max_value=1.0, value=0.9, step=0.01)
    st.session_state['max_seq_len'] = st.sidebar.slider('Max Sequence Length:', min_value=64, max_value=4096, value=2048, step=8)

    NEW_P = st.sidebar.text_area('Prompt before the chat starts. Edit here if desired:', PRE_PROMPT, height=60)
    if NEW_P != PRE_PROMPT and NEW_P != "" and NEW_P != None:
        st.session_state['pre_prompt'] = NEW_P + "\n\n"
    else:
        st.session_state['pre_prompt'] = PRE_PROMPT

    btn_col1, btn_col2 = st.sidebar.columns(2)

     # Acknowledgment button
    if st.sidebar.button("Ack"):
        st.write("[Go back to the blogging app](https://bloggy-s8e5.onrender.com/)")

   
    # Display chat history
    for message in st.session_state.chat_dialogue:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # User input
    if prompt := st.chat_input("Ask a question here to LLaMA2"):
        st.session_state.chat_dialogue.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
       
        # Assistant response
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            full_response = ""
            string_dialogue = st.session_state['pre_prompt']
            for dict_message in st.session_state.chat_dialogue:
                speaker = "User" if dict_message["role"] == "user" else "Assistant"
                try:
                    string_dialogue += f"{speaker}: {dict_message['content']}\n\n"
                except KeyError:
                # Handle the case where 'content' key is missing (optional: log a message)
                    pass

            output = debounce_replicate_run(
                st.session_state['llm'],
                string_dialogue + "Assistant: ",
                st.session_state['max_seq_len'],
                st.session_state['temperature'],
                st.session_state['top_p'],
                REPLICATE_API_TOKEN,
                REPLICATE_MODEL_ENDPOINTS[st.session_state['llm']]
            )
            for item in output:
                full_response += item
                message_placeholder.markdown(full_response + "â–Œ")
            message_placeholder.markdown(full_response)
        st.session_state.chat_dialogue.append({"role": "assistant", "content": full_response})

def main():
    render_app()

if __name__ == "__main__":
    main()



/** @type {import('tailwindcss').Config} */
export default {
  content: ["./src/**/*.{html,js,jsx}"],
  theme: {
    extend: {},
  },
  plugins: [],
}



import { defineConfig } from 'vite'
import react from '@vitejs/plugin-react'

// https://vitejs.dev/config/
export default defineConfig({
  plugins: [react()],
})


/* eslint-disable no-undef */
const express = require("express");
const bodyParser = require("body-parser");
const fs = require("fs");
const cors = require("cors");
const app = express();
const port = 5000;

// Enable CORS and parse JSON request bodies
app.use(cors());
app.use(bodyParser.json());

// Endpoint to get blog data
app.get("/api/blogs", (req, res) => {
  const filePath = "../src/assets/blogsData.json";
  // Read the blog data from the JSON file
  fs.readFile(filePath, (err, data) => {
    if (err) {
      // If there's an error reading the file, return a 500 error
      return res.status(500).send("Error reading file");
    }
    const blogs = JSON.parse(data);
    // Check if the data is an array
    if (!Array.isArray(blogs)) {
      // If the data is not an array, return a 500 error
      return res.status(500).send("Invalid data format");
    }
    // Return the blog data as JSON
    res.json(blogs);
  });
});

// Endpoint to save new blog data
app.post("/api/blogs", (req, res) => {
  const blogData = req.body;
  const filePath = "../src/assets/blogsData.json";

  // Read the existing blog data from the JSON file
  fs.readFile(filePath, (err, data) => {
    if (err) {
      // If the file doesn't exist, create a new one with the new blog data
      if (err.code === "ENOENT") {
        fs.writeFile(filePath, JSON.stringify([blogData], null, 2), (err) => {
          if (err) {
            // If there's an error writing the file, return a 500 error
            return res.status(500).send("Error writing file");
          }
          // Return a success message
          res.status(200).send("Blog data saved successfully");
        });
      } else {
        // If there's another error reading the file, return a 500 error
        return res.status(500).send("Error reading file");
      }
    } else {
      // If the file exists, parse the existing data and add the new blog data
      const existingData = JSON.parse(data);
      existingData.push(blogData);

      // Write the updated data to the file
      fs.writeFile(filePath, JSON.stringify(existingData, null, 2), (err) => {
        if (err) {
          // If there's an error writing the file, return a 500 error
          return res.status(500).send("Error 